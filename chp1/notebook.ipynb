{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tensorflow_core._api.v2.config' from '/usr/local/lib/python3.6/dist-packages/tensorflow_core/_api/v2/config/__init__.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "\n",
    "#@markdown This sets the warning status (default is `ignore`, since this notebook runs correctly)\n",
    "warning_status = \"ignore\" #@param [\"ignore\", \"always\", \"module\", \"once\", \"default\", \"error\"]\n",
    "import warnings\n",
    "warnings.filterwarnings(warning_status)\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(warning_status, category=DeprecationWarning)\n",
    "    warnings.filterwarnings(warning_status, category=UserWarning)\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "#@markdown This sets the styles of the plotting (default is styled like plots from [FiveThirtyeight.com](https://fivethirtyeight.com/)\n",
    "matplotlib_style = 'fivethirtyeight' #@param ['fivethirtyeight', 'bmh', 'ggplot', 'seaborn', 'default', 'Solarize_Light2', 'classic', 'dark_background', 'seaborn-colorblind', 'seaborn-notebook']\n",
    "import matplotlib.pyplot as plt; plt.style.use(matplotlib_style)\n",
    "import matplotlib.axes as axes;\n",
    "from matplotlib.patches import Ellipse\n",
    "#%matplotlib inline\n",
    "import seaborn as sns; sns.set_context('notebook')\n",
    "from IPython.core.pylabtools import figsize\n",
    "#@markdown This sets the resolution of the plot outputs (`retina` is the highest resolution)\n",
    "notebook_screen_res = 'retina' #@param ['retina', 'png', 'jpeg', 'svg', 'pdf']\n",
    "#%config InlineBackend.figure_format = notebook_screen_res\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "class _TFColor(object):\n",
    "    \"\"\"Enum of colors used in TF docs.\"\"\"\n",
    "    red = '#F15854'\n",
    "    blue = '#5DA5DA'\n",
    "    orange = '#FAA43A'\n",
    "    green = '#60BD68'\n",
    "    pink = '#F17CB0'\n",
    "    brown = '#B2912F'\n",
    "    purple = '#B276B2'\n",
    "    yellow = '#DECF3F'\n",
    "    gray = '#4D4D4D'\n",
    "    def __getitem__(self, i):\n",
    "        return [\n",
    "            self.red,\n",
    "            self.orange,\n",
    "            self.green,\n",
    "            self.blue,\n",
    "            self.pink,\n",
    "            self.brown,\n",
    "            self.purple,\n",
    "            self.yellow,\n",
    "            self.gray,\n",
    "        ][i % 9]\n",
    "TFColor = _TFColor()\n",
    "\n",
    "def session_options(enable_gpu_ram_resizing=True, enable_xla=False):\n",
    "    \"\"\"\n",
    "    Allowing the notebook to make use of GPUs if they're available.\n",
    "\n",
    "    XLA (Accelerated Linear Algebra) is a domain-specific compiler for linear\n",
    "    algebra that optimizes TensorFlow computations.\n",
    "    \"\"\"\n",
    "    config = tf.config\n",
    "    gpu_devices = config.experimental.list_physical_devices('GPU')\n",
    "    if enable_gpu_ram_resizing:\n",
    "        for device in gpu_devices:\n",
    "           tf.config.experimental.set_memory_growth(device, True)\n",
    "    if enable_xla:\n",
    "        config.optimizer.set_jit(True)\n",
    "    return config\n",
    "\n",
    "session_options(enable_gpu_ram_resizing=True, enable_xla=True)\n",
    "import pprint\n",
    "pr = pprint.pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Tensor: shape=(12,), dtype=int32, numpy=\n",
      "array([   0,    0,    1,    2,    2,    3,    4,    7,   22,  259,  506,\n",
      "       1017], dtype=int32)>\n"
     ]
    }
   ],
   "source": [
    "# building graph\n",
    "con = tf.constant\n",
    "rv_coin_flip_prior = tfp.distributions.Bernoulli(probs=0.5, dtype=tf.int32)\n",
    "num_trials = con([0, 1, 2, 3, 4, 5, 8, 15, 50, 500, 1000, 2000])\n",
    "coin_flip_data = rv_coin_flip_prior.sample(num_trials[-1])\n",
    "# prepend 0 for zeroth flip\n",
    "coin_flip_data = tf.pad(coin_flip_data, con([[1, 0]]), \"CONSTANT\")\n",
    "# cumulative head counts and grab them at diff number of trials\n",
    "cumulative_headcounts = tf.gather(tf.cumsum(coin_flip_data), num_trials)\n",
    "pr(cumulative_headcounts)\n",
    "alpha = tf.cast(1 + cumulative_headcounts, tf.float32) \n",
    "beta = tf.cast(1 + num_trials - cumulative_headcounts, tf.float32)\n",
    "rv_observed_heads = tfp.distributions.Beta(concentration1=alpha, concentration0=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}